{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ddyQ8HE8zeYj"
      },
      "outputs": [
        {
          "ename": "ConnectionError",
          "evalue": "HTTPConnectionPool(host='localhost', port=3000): Max retries exceeded with url: /socket.io/?transport=polling&EIO=4&t=1685206380.9095728 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020CF8D6EED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m@sio\u001b[39m\u001b[39m.\u001b[39mevent\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprediction_result\u001b[39m(data):\n\u001b[0;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPrediction:\u001b[39m\u001b[39m'\u001b[39m, data)\n\u001b[1;32m---> 19\u001b[0m sio\u001b[39m.\u001b[39;49mconnect(\u001b[39m'\u001b[39;49m\u001b[39mhttp://localhost:3000\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\socketio\\client.py:338\u001b[0m, in \u001b[0;36mClient.connect\u001b[1;34m(self, url, headers, auth, transports, namespaces, socketio_path, wait, wait_timeout)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[39mexcept\u001b[39;00m engineio\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trigger_event(\n\u001b[0;32m    336\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mconnect_error\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    337\u001b[0m         exc\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(exc\u001b[39m.\u001b[39margs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m exc\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 338\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mConnectionError(exc\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m    341\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_event\u001b[39m.\u001b[39mwait(timeout\u001b[39m=\u001b[39mwait_timeout):\n",
            "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=3000): Max retries exceeded with url: /socket.io/?transport=polling&EIO=4&t=1685206380.9095728 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000020CF8D6EED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
          ]
        }
      ],
      "source": [
        "# pip install python-socketio\n",
        "import socketio\n",
        "\n",
        "sio = socketio.Client()\n",
        "\n",
        "@sio.event\n",
        "def connect():\n",
        "    print('Connected to server')\n",
        "\n",
        "@sio.event\n",
        "def disconnect():\n",
        "    print('Disconnected from server')\n",
        "    exit()\n",
        "\n",
        "@sio.event\n",
        "def prediction_result(data):\n",
        "    print('Prediction:', data)\n",
        "\n",
        "sio.connect('http://localhost:3000')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3vj15Vde0Gxs"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "# !pip3 install face_recognition\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# import face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C3r-9rMc1DmO"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "from torch import nn\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "g1G0IoVy2Pc7"
      },
      "outputs": [],
      "source": [
        "#Model with feature visualization\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
        "        super(Model, self).__init__()\n",
        "        model = models.resnext50_32x4d(pretrained = True)\n",
        "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
        "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "        self.linear1 = nn.Linear(2048,num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    def forward(self, x):\n",
        "        batch_size,seq_length, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        fmap = self.model(x)\n",
        "        x = self.avgpool(fmap)\n",
        "        x = x.view(batch_size,seq_length,2048)\n",
        "        x_lstm,_ = self.lstm(x,None)\n",
        "        return fmap,self.dp(self.linear1(x_lstm[:,-1,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "avpp16KLze7T"
      },
      "outputs": [],
      "source": [
        "im_size = 112\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "sm = nn.Softmax()\n",
        "inv_normalize =  transforms.Normalize(mean=-1*np.divide(mean,std),std=np.divide([1,1,1],std))\n",
        "def im_convert(tensor):\n",
        "    \"\"\" Display a tensor as an image. \"\"\"\n",
        "    image = tensor.to(\"cpu\").clone().detach()\n",
        "    image = image.squeeze()\n",
        "    image = inv_normalize(image)\n",
        "    image = image.numpy()\n",
        "    image = image.transpose(1,2,0)\n",
        "    image = image.clip(0, 1)\n",
        "    cv2.imwrite('./v2.jpg',image*255)\n",
        "    return image\n",
        "\n",
        "def predict(model,img,path = './'):\n",
        "  fmap,logits = model(img.to('cpu'))\n",
        "  params = list(model.parameters())\n",
        "  weight_softmax = model.linear1.weight.detach().cpu().numpy()\n",
        "  logits = sm(logits)\n",
        "  _,prediction = torch.max(logits,1)\n",
        "  confidence = logits[:,int(prediction.item())].item()*100\n",
        "  print('confidence of prediction:',logits[:,int(prediction.item())].item()*100)\n",
        "  idx = np.argmax(logits.detach().cpu().numpy())\n",
        "  bz, nc, h, w = fmap.shape\n",
        "  out = np.dot(fmap[-1].detach().cpu().numpy().reshape((nc, h*w)).T,weight_softmax[idx,:].T)\n",
        "  predict = out.reshape(h,w)\n",
        "  predict = predict - np.min(predict)\n",
        "  predict_img = predict / np.max(predict)\n",
        "  predict_img = np.uint8(255*predict_img)\n",
        "  out = cv2.resize(predict_img, (im_size,im_size))\n",
        "  heatmap = cv2.applyColorMap(out, cv2.COLORMAP_JET)\n",
        "  img = im_convert(img[:,-1,:,:,:])\n",
        "  result = heatmap * 0.5 + img*0.8*255\n",
        "  cv2.imwrite('v1.png',result)\n",
        "  result1 = heatmap * 0.5/255 + img*0.8\n",
        "  r,g,b = cv2.split(result1)\n",
        "  result1 = cv2.merge((r,g,b))\n",
        "  plt.imshow(result1)\n",
        "  plt.show()\n",
        "  return [int(prediction.item()),confidence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "asSbpP8fzlFj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class validation_dataset(Dataset):\n",
        "    def __init__(self,video_names,sequence_length=60,transform=None):\n",
        "        self.video_names = video_names\n",
        "        self.transform = transform\n",
        "        self.count = sequence_length\n",
        "        self.face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.video_names)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        video_path = self.video_names[idx]\n",
        "        frames = []\n",
        "        a = int(100/self.count)\n",
        "        first_frame = np.random.randint(0,a)      \n",
        "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
        "            # Use Haar Cascades classifier for face detection\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "            \n",
        "            try:\n",
        "                # Crop the frame around the first detected face\n",
        "                (x, y, w, h) = faces[0]\n",
        "                frame = frame[y:y+h, x:x+w]\n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "            frames.append(self.transform(frame))\n",
        "            if(len(frames) == self.count):\n",
        "              break\n",
        "              \n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.count]\n",
        "        return frames.unsqueeze(0)\n",
        "    \n",
        "    def frame_extract(self,path):\n",
        "      vidObj = cv2.VideoCapture(path) \n",
        "      success = 1\n",
        "      while success:\n",
        "          success, image = vidObj.read()\n",
        "          if success:\n",
        "              yield image\n",
        "\n",
        "def im_plot(tensor):\n",
        "    image = tensor.cpu().numpy().transpose(1,2,0)\n",
        "    b,g,r = cv2.split(image)\n",
        "    image = cv2.merge((r,g,b))\n",
        "    image = image*[0.22803, 0.22145, 0.216989] +  [0.43216, 0.394666, 0.37645]\n",
        "    image = image*255.0\n",
        "    plt.imshow(image.astype(int))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J8YkC-vwzrkE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test : [real1].mp4\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "stack expects a non-empty TensorList",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(path_to_videos)):\n\u001b[0;32m     20\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest : \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mpath_to_videos[i])\n\u001b[1;32m---> 21\u001b[0m   prediction \u001b[39m=\u001b[39m predict(model,video_dataset[i],\u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m   \u001b[39mif\u001b[39;00m prediction[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mREAL\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[5], line 42\u001b[0m, in \u001b[0;36mvalidation_dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mlen\u001b[39m(frames) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount):\n\u001b[0;32m     40\u001b[0m       \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m frames \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(frames)\n\u001b[0;32m     43\u001b[0m frames \u001b[39m=\u001b[39m frames[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount]\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m frames\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
          ]
        }
      ],
      "source": [
        "#Code for making prediction\n",
        "im_size = 112\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "\n",
        "path_to_videos= [\"[real1].mp4\"]\n",
        "\n",
        "video_dataset = validation_dataset(path_to_videos,sequence_length = 20,transform = train_transforms)\n",
        "model = Model(2).cpu()\n",
        "path_to_model = 'model_84_acc_10_frames_final_data.pt'\n",
        "model.load_state_dict(torch.load(path_to_model, map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "for i in range(0,len(path_to_videos)):\n",
        "  print(\"test : \"+path_to_videos[i])\n",
        "  prediction = predict(model,video_dataset[i],'./')\n",
        "  if prediction[0] == 1:\n",
        "    print(\"REAL\")\n",
        "    sio.emit('prediction', \"REAL\")\n",
        "  else:\n",
        "    print(\"FAKE\")\n",
        "    sio.emit('prediction', \"FAKE\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
